{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214b9fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diplomado de Inteligencia Artificial y Machine Learning\n",
    "# Sesión de Aprendizaje Supervisado: Clasificación (Código Completo)\n",
    "\n",
    "# Instalamos librerías necesarias\n",
    "!pip install scikit-learn matplotlib --quiet\n",
    "\n",
    "# Importamos librerías\n",
    "from sklearn.datasets import load_iris, load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ----------------------\n",
    "# Dataset Iris\n",
    "# ----------------------\n",
    "print(\"=== Dataset Iris ===\")\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# ----------------------\n",
    "# Ejemplo 1: Regresión Logística\n",
    "# ----------------------\n",
    "print(\"\\n=== Ejemplo 1: Regresión Logística ===\")\n",
    "model_logreg = LogisticRegression(max_iter=200)\n",
    "model_logreg.fit(X_train, y_train)\n",
    "y_pred_logreg = model_logreg.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred_logreg))\n",
    "print(\"Matriz de confusión:\\n\", confusion_matrix(y_test, y_pred_logreg))\n",
    "\n",
    "# ----------------------\n",
    "# Ejemplo 2: Árbol de Decisión\n",
    "# ----------------------\n",
    "print(\"\\n=== Ejemplo 2: Árbol de Decisión ===\")\n",
    "model_tree = DecisionTreeClassifier()\n",
    "model_tree.fit(X_train, y_train)\n",
    "y_pred_tree = model_tree.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred_tree))\n",
    "print(\"Matriz de confusión:\\n\", confusion_matrix(y_test, y_pred_tree))\n",
    "\n",
    "# Visualizar el árbol\n",
    "plt.figure(figsize=(12,8))\n",
    "plot_tree(model_tree, filled=True, feature_names=iris.feature_names, class_names=iris.target_names)\n",
    "plt.show()\n",
    "\n",
    "# ----------------------\n",
    "# Ejemplo 3: Máquina de Vectores de Soporte (SVM)\n",
    "# ----------------------\n",
    "print(\"\\n=== Ejemplo 3: SVM ===\")\n",
    "model_svm = SVC()\n",
    "model_svm.fit(X_train, y_train)\n",
    "y_pred_svm = model_svm.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred_svm))\n",
    "print(\"Matriz de confusión:\\n\", confusion_matrix(y_test, y_pred_svm))\n",
    "\n",
    "# ----------------------\n",
    "# Dataset Wine\n",
    "# ----------------------\n",
    "print(\"\\n=== Dataset Wine ===\")\n",
    "wine = load_wine()\n",
    "X_wine = wine.data\n",
    "y_wine = wine.target\n",
    "\n",
    "X_train_wine, X_test_wine, y_train_wine, y_test_wine = train_test_split(X_wine, y_wine, test_size=0.3, random_state=42)\n",
    "\n",
    "# ----------------------\n",
    "# Ejemplo 4: K-Nearest Neighbors (KNN)\n",
    "# ----------------------\n",
    "print(\"\\n=== Ejemplo 4: KNN ===\")\n",
    "model_knn = KNeighborsClassifier(n_neighbors=5)\n",
    "model_knn.fit(X_train_wine, y_train_wine)\n",
    "y_pred_knn = model_knn.predict(X_test_wine)\n",
    "\n",
    "print(classification_report(y_test_wine, y_pred_knn))\n",
    "print(\"Matriz de confusión:\\n\", confusion_matrix(y_test_wine, y_pred_knn))\n",
    "\n",
    "# ----------------------\n",
    "# Ejemplo 5: Naive Bayes\n",
    "# ----------------------\n",
    "print(\"\\n=== Ejemplo 5: Naive Bayes ===\")\n",
    "model_nb = GaussianNB()\n",
    "model_nb.fit(X_train_wine, y_train_wine)\n",
    "y_pred_nb = model_nb.predict(X_test_wine)\n",
    "\n",
    "print(classification_report(y_test_wine, y_pred_nb))\n",
    "print(\"Matriz de confusión:\\n\", confusion_matrix(y_test_wine, y_pred_nb))\n",
    "\n",
    "# ----------------------\n",
    "# Explicación General:\n",
    "# ----------------------\n",
    "print(\"\\nExplicación General:\")\n",
    "print(\"- Regresión Logística: útil cuando la relación entre variables es lineal.\")\n",
    "print(\"- Árbol de Decisión: bueno para interpretar fácilmente decisiones.\")\n",
    "print(\"- SVM: potente en espacios de alta dimensión, usa márgenes.\")\n",
    "print(\"- KNN: clasifica basado en los vecinos más cercanos.\")\n",
    "print(\"- Naive Bayes: se basa en la probabilidad, rápido y eficiente.\")\n",
    "\n",
    "print(\"\\n¡Fin del notebook!\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
